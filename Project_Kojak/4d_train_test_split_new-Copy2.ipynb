{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import y data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"../Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {\n",
    "    0:  \"Nucleoplasm\",  \n",
    "    1:  \"Nuclear membrane\",   \n",
    "    2:  \"Nucleoli\",   \n",
    "    3:  \"Nucleoli fibrillar center\",   \n",
    "    4:  \"Nuclear speckles\",\n",
    "    5:  \"Nuclear bodies\",   \n",
    "    6:  \"Endoplasmic reticulum\",   \n",
    "    7:  \"Golgi apparatus\",   \n",
    "    8:  \"Peroxisomes\",   \n",
    "    9:  \"Endosomes\",   \n",
    "    10:  \"Lysosomes\",   \n",
    "    11:  \"Intermediate filaments\",   \n",
    "    12:  \"Actin filaments\",   \n",
    "    13:  \"Focal adhesion sites\",   \n",
    "    14:  \"Microtubules\",   \n",
    "    15:  \"Microtubule ends\",   \n",
    "    16:  \"Cytokinetic bridge\",   \n",
    "    17:  \"Mitotic spindle\",   \n",
    "    18:  \"Microtubule organizing center\",   \n",
    "    19:  \"Centrosome\",   \n",
    "    20:  \"Lipid droplets\",   \n",
    "    21:  \"Plasma membrane\",   \n",
    "    22:  \"Cell junctions\",   \n",
    "    23:  \"Mitochondria\",   \n",
    "    24:  \"Aggresome\",   \n",
    "    25:  \"Cytosol\",   \n",
    "    26:  \"Cytoplasmic bodies\",   \n",
    "    27:  \"Rods & rings\"\n",
    "}\n",
    "\n",
    "# reverse_train_labels = dict((v,k) for k,v in label_names.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in label_names.keys():\n",
    "    train_labels[label_names[key]] = 0\n",
    "    \n",
    "def fill_targets(row):\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    for num in row.Target:\n",
    "        name = label_names[int(num)]\n",
    "        row.loc[name] = 1\n",
    "    return row\n",
    "\n",
    "\n",
    "train_labels = train_labels.apply(fill_targets, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many samples are in each category and store that in \"counts\". Then create a new minority label that picks the smallest class for a given sample. We will then stratify based on this lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_labels\n",
    "y.columns =['Id', 'Target', 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]\n",
    "y = y[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = y.sum(axis=0).sort_values(ascending=False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority = []\n",
    "for label in train_labels['Target']:\n",
    "    if len(label)==1:\n",
    "        minority.append(label[0])\n",
    "    else:\n",
    "        counts_list = []\n",
    "        for i in label:\n",
    "            counts_list.append(counts[i])\n",
    "        min_index = counts_list.index(min(counts_list))\n",
    "        minority.append(label[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['minority_class'] = minority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split on minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split = np.array(train_labels['minority_class'])\n",
    "X_split = np.zeros(len(y_split)) # Using a dummy X for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=47)\n",
    "ind = folds.split(X_split,y_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes = []\n",
    "test_indexes = []\n",
    "for train_index, test_index in ind:\n",
    "    train_indexes.append(train_index)\n",
    "    test_indexes.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_minority = [y_split[i] for i in train_indexes[1]]\n",
    "y_test_minority = [y_split[i] for i in test_indexes[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train = y.ix[train_indexes[1]]\n",
    "y_test = y.ix[test_indexes[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train_target = train_labels.ix[train_indexes[1]]\n",
    "y_test_target = train_labels.ix[test_indexes[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that they appear in similar distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split training data (to use in model selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub_split = np.array(y_train_target['minority_class'])\n",
    "X_sub_split = np.zeros(len(y_sub_split)) # Using a dummy X for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sub_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state = 4)\n",
    "sub_ind = sub_folds.split(X_sub_split,y_sub_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_indexes = []\n",
    "sub_test_indexes = []\n",
    "for train_index, test_index in sub_ind:\n",
    "    sub_train_indexes.append(train_index)\n",
    "    sub_test_indexes.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_minority_sub = [y_sub_split[i] for i in sub_train_indexes[1]]\n",
    "y_test_minority_sub = [y_sub_split[i] for i in sub_test_indexes[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_sub = y.ix[sub_train_indexes[1]]\n",
    "y_test_sub = y.ix[sub_test_indexes[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_target_sub = train_labels.ix[sub_train_indexes[1]]\n",
    "y_test_target_sub = train_labels.ix[sub_test_indexes[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that they appear in similar distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting training data to only single label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "for label in y_train_target['Target']:\n",
    "    if len(label)==1:\n",
    "        cat.append(label[0])\n",
    "    else:\n",
    "        cat.append(28)\n",
    "# Make a new category (28) for all multi label images\n",
    "\n",
    "\n",
    "cat_sub = []\n",
    "for label in y_train_target_sub['Target']:\n",
    "    if len(label)==1:\n",
    "        cat_sub.append(label[0])\n",
    "    else:\n",
    "        cat_sub.append(28)\n",
    "# Make a new category (28) for all multi label images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_target['multi_label'] = cat\n",
    "\n",
    "y_train_target_sub['multi_label'] = cat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_s_train_target = y_train_target[y_train_target['multi_label']!=28]\n",
    "y_s_train = y_s_train_target[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]\n",
    "\n",
    "y_s_train_target_sub = y_train_target_sub[y_train_target_sub['multi_label']!=28]\n",
    "y_s_train_sub = y_s_train_target_sub[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "for label in y_test_target['Target']:\n",
    "    if len(label)==1:\n",
    "        cat.append(label[0])\n",
    "    else:\n",
    "        cat.append(28)\n",
    "# Make a new category (28) for all multi label images\n",
    "\n",
    "\n",
    "cat_sub = []\n",
    "for label in y_test_target_sub['Target']:\n",
    "    if len(label)==1:\n",
    "        cat_sub.append(label[0])\n",
    "    else:\n",
    "        cat_sub.append(28)\n",
    "# Make a new category (28) for all multi label images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_target['multi_label'] = cat\n",
    "\n",
    "y_test_target_sub['multi_label'] = cat_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_s_test_target = y_test_target[y_test_target['multi_label']!=28]\n",
    "y_s_test = y_s_test_target[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]\n",
    "\n",
    "y_s_test_target_sub = y_test_target_sub[y_test_target_sub['multi_label']!=28]\n",
    "y_s_test_sub = y_s_test_target_sub[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sl_indexes = y_s_train.index.values\n",
    "test_sl_indexes = y_s_test.index.values\n",
    "\n",
    "\n",
    "train_sl_indexes_sub = y_s_train_sub.index.values\n",
    "test_sl_indexes_sub = y_s_test_sub.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to only categories 4 and 21, which are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1931\n",
      "1 221\n",
      "2 651\n",
      "3 519\n",
      "4 864\n",
      "5 775\n",
      "6 501\n",
      "7 924\n",
      "8 25\n",
      "9 13\n",
      "10 0\n",
      "11 482\n",
      "12 183\n",
      "13 126\n",
      "14 389\n",
      "15 0\n",
      "16 21\n",
      "17 0\n",
      "18 253\n",
      "19 411\n",
      "20 79\n",
      "21 851\n",
      "22 167\n",
      "23 1331\n",
      "24 96\n",
      "25 1170\n",
      "26 107\n",
      "27 1\n"
     ]
    }
   ],
   "source": [
    "counts_2cat = y_s_train.sum(axis=0).values\n",
    "for i,count in enumerate(counts_2cat):\n",
    "    print(i,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_2cat = [4,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     213\n",
      "21    207\n",
      "dtype: int64\n",
      "None\n",
      "4     165\n",
      "21    197\n",
      "dtype: int64\n",
      "None\n",
      "4     666\n",
      "21    650\n",
      "dtype: int64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# y_s_train_2cat = y_s_train[[selection[0],selection[1]]]\n",
    "# y_s_train_2cat = y_s_train_2cat[y_s_train_2cat.sum(axis=1) != 0 ]\n",
    "# print(len(y_s_train_2cat))\n",
    "# print(print(y_s_train_2cat.sum(axis=0)))\n",
    "\n",
    "y_s_test_2cat = y_s_test[[selection_2cat[0],selection_2cat[1]]]\n",
    "y_s_test_2cat = y_s_test_2cat[y_s_test_2cat.sum(axis=1) != 0 ]\n",
    "print(print(y_s_test_2cat.sum(axis=0)))\n",
    "\n",
    "\n",
    "y_s_test_sub_2cat = y_s_test_sub[[selection_2cat[0],selection_2cat[1]]]\n",
    "y_s_test_sub_2cat = y_s_test_sub_2cat[y_s_test_sub_2cat.sum(axis=1) != 0 ]\n",
    "print(print(y_s_test_sub_2cat.sum(axis=0)))\n",
    "\n",
    "y_s_train_sub_2cat = y_s_train_sub[[selection_2cat[0],selection_2cat[1]]]\n",
    "y_s_train_sub_2cat = y_s_train_sub_2cat[y_s_train_sub_2cat.sum(axis=1) != 0 ]\n",
    "print(print(y_s_train_sub_2cat.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_s_indexes_2cat = y_s_train_2cat.index.values\n",
    "test_s_indexes_2cat = y_s_test_2cat.index.values\n",
    "\n",
    "train_s_indexes_sub_2cat = y_s_train_sub_2cat.index.values\n",
    "test_s_indexes_sub_2cat = y_s_test_sub_2cat.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to only 3 categories: 4, 5 and 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1931\n",
      "1 221\n",
      "2 651\n",
      "3 519\n",
      "4 864\n",
      "5 775\n",
      "6 501\n",
      "7 924\n",
      "8 25\n",
      "9 13\n",
      "10 0\n",
      "11 482\n",
      "12 183\n",
      "13 126\n",
      "14 389\n",
      "15 0\n",
      "16 21\n",
      "17 0\n",
      "18 253\n",
      "19 411\n",
      "20 79\n",
      "21 851\n",
      "22 167\n",
      "23 1331\n",
      "24 96\n",
      "25 1170\n",
      "26 107\n",
      "27 1\n"
     ]
    }
   ],
   "source": [
    "counts_3 = y_s_train.sum(axis=0).values\n",
    "for i,count in enumerate(counts_3):\n",
    "    print(i,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_3 = [4,5,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     213\n",
      "5     208\n",
      "21    207\n",
      "dtype: int64\n",
      "None\n",
      "4     165\n",
      "5     154\n",
      "21    197\n",
      "dtype: int64\n",
      "None\n",
      "4     666\n",
      "5     623\n",
      "21    650\n",
      "dtype: int64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y_s_test_3cat = y_s_test[selection_3]\n",
    "y_s_test_3cat = y_s_test_3cat[y_s_test_3cat.sum(axis=1) != 0 ]\n",
    "print(print(y_s_test_3cat.sum(axis=0)))\n",
    "\n",
    "y_s_test_sub_3cat = y_s_test_sub[selection_3]\n",
    "y_s_test_sub_3cat = y_s_test_sub_3cat[y_s_test_sub_3cat.sum(axis=1) != 0 ]\n",
    "print(print(y_s_test_sub_3cat.sum(axis=0)))\n",
    "\n",
    "y_s_train_sub_3cat = y_s_train_sub[selection_3]\n",
    "y_s_train_sub_3cat = y_s_train_sub_3cat[y_s_train_sub_3cat.sum(axis=1) != 0 ]\n",
    "print(print(y_s_train_sub_3cat.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_s_indexes_3cat = y_s_train_3cat.index.values\n",
    "test_s_indexes_3cat = y_s_test_3cat.index.values\n",
    "\n",
    "train_s_indexes_sub_3cat = y_s_train_sub_3cat.index.values\n",
    "test_s_indexes_sub_3cat = y_s_test_sub_3cat.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to any category with more than 200 individually labeled data points and 700 multi-labeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10273\n",
      "1 1011\n",
      "2 2892\n",
      "3 1251\n",
      "4 1485\n",
      "5 2032\n",
      "6 811\n",
      "7 2243\n",
      "8 43\n",
      "9 35\n",
      "10 22\n",
      "11 872\n",
      "12 557\n",
      "13 432\n",
      "14 853\n",
      "15 17\n",
      "16 419\n",
      "17 164\n",
      "18 725\n",
      "19 1191\n",
      "20 134\n",
      "21 3044\n",
      "22 638\n",
      "23 2378\n",
      "24 259\n",
      "25 6584\n",
      "26 262\n",
      "27 9\n"
     ]
    }
   ],
   "source": [
    "counts_3 = y_train.sum(axis=0).values\n",
    "for i,count in enumerate(counts_3):\n",
    "    print(i,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "enough_data = [0,1,2,3,4,5,6,7,11,14,18,19,21,23,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enough_data = y_test[enough_data]\n",
    "y_test_enough_data = y_test_enough_data[y_test_enough_data.sum(axis=1) != 0 ]\n",
    "# print(print(y_test_enough_data.sum(axis=0)))\n",
    "\n",
    "y_test_sub_enough_data = y_test_sub[enough_data]\n",
    "y_test_sub_enough_data = y_test_sub_enough_data[y_test_sub_enough_data.sum(axis=1) != 0 ]\n",
    "# print(print(y_test_sub_enough_data.sum(axis=0)))\n",
    "\n",
    "y_train_sub_enough_data = y_train_sub[enough_data]\n",
    "y_train_sub_enough_data = y_train_sub_enough_data[y_train_sub_enough_data.sum(axis=1) != 0 ]\n",
    "# print(print(y_train_sub_enough_data.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_s_indexes_3cat = y_s_train_3cat.index.values\n",
    "test_indexes_enough_data = y_test_enough_data.index.values\n",
    "\n",
    "train_indexes_sub_enough_data = y_train_sub_enough_data.index.values\n",
    "test_indexes_sub_enough_data = y_test_sub_enough_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enough Data (at least 200 examples) single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1931\n",
      "1 221\n",
      "2 651\n",
      "3 519\n",
      "4 864\n",
      "5 775\n",
      "6 501\n",
      "7 924\n",
      "8 25\n",
      "9 13\n",
      "10 0\n",
      "11 482\n",
      "12 183\n",
      "13 126\n",
      "14 389\n",
      "15 0\n",
      "16 21\n",
      "17 0\n",
      "18 253\n",
      "19 411\n",
      "20 79\n",
      "21 851\n",
      "22 167\n",
      "23 1331\n",
      "24 96\n",
      "25 1170\n",
      "26 107\n",
      "27 1\n"
     ]
    }
   ],
   "source": [
    "counts_3 = y_s_train.sum(axis=0).values\n",
    "for i,count in enumerate(counts_3):\n",
    "    print(i,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "enough_data = [0,1,2,3,4,5,6,7,11,14,18,19,21,23,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s_test_enough_data = y_s_test[enough_data]\n",
    "y_s_test_enough_data = y_s_test_enough_data[y_s_test_enough_data.sum(axis=1) != 0 ]\n",
    "# print(print(y_test_enough_data.sum(axis=0)))\n",
    "\n",
    "y_s_test_sub_enough_data = y_s_test_sub[enough_data]\n",
    "y_s_test_sub_enough_data = y_s_test_sub_enough_data[y_s_test_sub_enough_data.sum(axis=1) != 0 ]\n",
    "# print(print(y_test_sub_enough_data.sum(axis=0)))\n",
    "\n",
    "y_s_train_sub_enough_data = y_s_train_sub[enough_data]\n",
    "y_s_train_sub_enough_data = y_s_train_sub_enough_data[y_s_train_sub_enough_data.sum(axis=1) != 0 ]\n",
    "# print(print(y_train_sub_enough_data.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_s_indexes_3cat = y_s_train_3cat.index.values\n",
    "test_indexes_enough_data = y_test_enough_data.index.values\n",
    "\n",
    "train_indexes_sub_enough_data = y_train_sub_enough_data.index.values\n",
    "test_indexes_sub_enough_data = y_test_sub_enough_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing 4D Image Data (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our file names and define some important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "input_pixels = 512\n",
    "cnn_pixels = 512 \n",
    "colors = 4\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in each image and stack them in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.transform import resize\n",
    "# from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "# ##################################################################################################\n",
    "# fpath = []\n",
    "# for image_id in np.array(train_labels['Id']):\n",
    "#     path = \"../Data/train/\"+ image_id\n",
    "#     fpath.append(path)\n",
    "\n",
    "# X = np.empty(shape=(len(train_labels['Id']),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "\n",
    "# for i, fpath in enumerate(fpath):\n",
    "#     images = np.zeros(shape=(input_pixels,input_pixels,colors))\n",
    "#     images[:,:,0] = imread(fpath + \"_green\" + \".png\")\n",
    "#     images[:,:,1] = imread(fpath + \"_red\" + \".png\")\n",
    "#     images[:,:,2] = imread(fpath + \"_blue\" + \".png\")\n",
    "#     images[:,:,3] = imread(fpath + \"_yellow\" + \".png\")\n",
    "#     images = resize(images, (cnn_pixels, cnn_pixels, colors), preserve_range=True).astype(np.float32)\n",
    "#     images = preprocess_input(images)\n",
    "#     X[i, ...] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import listdir\n",
    "\n",
    "# # SAVE\n",
    "# ##################################################################################################\n",
    "# import tables\n",
    "# h5file = tables.open_file('Generated_Files/4d_image_data_512.h5', mode='w', title=\"3d_image_data\")\n",
    "# root = h5file.root\n",
    "# h5file.create_array(root, \"image_data_rgby\", X)\n",
    "# h5file.close()\n",
    "\n",
    "# # OPEN\n",
    "# ##################################################################################################\n",
    "X = np.empty(shape=(len(train_labels['Id']),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "import tables\n",
    "hdf5_file = tables.open_file('Generated_Files/4d_image_data_512.h5', mode='r')\n",
    "X[:,:,:,:] = np.array(hdf5_file.root.image_data_rgby)\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Label, 2 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_s_train_2cat = np.array([X[i] for i in train_s_indexes_2cat])\n",
    "X_s_test_2cat = np.empty(shape=(len(y_s_test_2cat),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_s_test_2cat = np.array([X[i] for i in test_s_indexes_2cat])\n",
    "\n",
    "X_s_train_sub_2cat = np.empty(shape=(len(y_s_train_sub_2cat),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_s_train_sub_2cat = np.array([X[i] for i in train_s_indexes_sub_2cat])\n",
    "\n",
    "X_s_test_sub_2cat = np.empty(shape=(len(y_s_test_sub_2cat),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_s_test_sub_2cat = np.array([X[i] for i in test_s_indexes_sub_2cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "import tables\n",
    "##################################################################################################\n",
    "h5file = tables.open_file('Generated_Files/4d_small_train_data_2categories.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_s_train_2cat\", np.array(X_s_train_sub_2cat))\n",
    "h5file.create_array(root, \"y_s_train_2cat\", np.array(y_s_train_sub_2cat))\n",
    "h5file.create_array(root, \"X_s_test_2cat\", np.array(X_s_test_sub_2cat))\n",
    "h5file.create_array(root, \"y_s_test_2cat\", np.array(y_s_test_sub_2cat))\n",
    "h5file.close()\n",
    "\n",
    "h5file = tables.open_file('Generated_Files/4d_small_test_data_2categories.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_s_test_2cat\", np.array(X_s_test_2cat))\n",
    "h5file.create_array(root, \"y_s_test_2cat\", np.array(y_s_test_2cat))\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Label, 3 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s_test_3cat = np.array([X[i] for i in test_s_indexes_3cat])\n",
    "\n",
    "X_s_train_sub_3cat = np.array([X[i] for i in train_s_indexes_sub_3cat])\n",
    "X_s_test_sub_3cat = np.array([X[i] for i in test_s_indexes_sub_3cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "# SAVE\n",
    "##################################################################################################\n",
    "h5file = tables.open_file('Generated_Files/4d_small_train_data_3categories.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_s_train_3cat\", np.array(X_s_train_sub_3cat))\n",
    "h5file.create_array(root, \"y_s_train_3cat\", np.array(y_s_train_sub_3cat))\n",
    "h5file.create_array(root, \"X_s_test_3cat\", np.array(X_s_test_sub_3cat))\n",
    "h5file.create_array(root, \"y_s_test_3cat\", np.array(y_s_test_sub_3cat))\n",
    "h5file.close()\n",
    "\n",
    "h5file = tables.open_file('Generated_Files/4d_small_test_data_3categories.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_s_test_3cat\", np.array(X_s_test_3cat))\n",
    "h5file.create_array(root, \"y_s_test_3cat\", np.array(y_s_test_3cat))\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Labels, All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s_test = np.empty(shape=(len(y_s_test),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_s_test = np.array([X[i] for i in test_sl_indexes])\n",
    "\n",
    "X_s_train_sub = np.empty(shape=(len(y_s_train_sub),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_s_train_sub = np.array([X[i] for i in train_sl_indexes_sub])\n",
    "\n",
    "X_s_test_sub = np.empty(shape=(len(y_s_test_sub),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_s_test_sub = np.array([X[i] for i in test_sl_indexes_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "##################################################################################################\n",
    "h5file = tables.open_file('Generated_Files/4d_small_train_data.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_s_train\", np.array(X_s_train_sub))\n",
    "h5file.create_array(root, \"y_s_train\", np.array(y_s_train_sub))\n",
    "h5file.create_array(root, \"X_s_test\", np.array(X_s_test_sub))\n",
    "h5file.create_array(root, \"y_s_test\", np.array(y_s_test_sub))\n",
    "h5file.close()\n",
    "\n",
    "h5file = tables.open_file('Generated_Files/4d_small_test_data.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_s_test\", np.array(X_s_test))\n",
    "h5file.create_array(root, \"y_s_test\", np.array(y_s_test))\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enough data (At least 100 individual and 700 multi labels each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enough_data = np.empty(shape=(len(y_test_enough_data),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_test_enough_data = np.array([X[i] for i in test_indexes_enough_data])\n",
    "\n",
    "X_train_sub_enough_data = np.empty(shape=(len(y_train_sub_enough_data),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_train_sub_enough_data = np.array([X[i] for i in train_indexes_sub_enough_data])\n",
    "\n",
    "X_test_sub_enough_data = np.empty(shape=(len(y_test_sub_enough_data),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_test_sub_enough_data = np.array([X[i] for i in test_indexes_sub_enough_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "##################################################################################################\n",
    "h5file = tables.open_file('Generated_Files/4d_enough_train_data.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_train\", np.array(X_train_sub_enough_data))\n",
    "h5file.create_array(root, \"y_train\", np.array(y_train_sub_enough_data))\n",
    "h5file.create_array(root, \"X_test\", np.array(X_test_sub_enough_data))\n",
    "h5file.create_array(root, \"y_test\", np.array(y_test_sub_enough_data))\n",
    "h5file.close()\n",
    "\n",
    "h5file = tables.open_file('Generated_Files/4d_enough_test_data.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_test\", np.array(X_test_enough_data))\n",
    "h5file.create_array(root, \"y_test\", np.array(y_test_enough_data))\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19192, 15)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sub_enough_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2078\n",
      "1 204\n",
      "2 571\n",
      "3 267\n",
      "4 284\n",
      "5 370\n",
      "6 166\n",
      "7 489\n",
      "8 155\n",
      "9 168\n",
      "10 119\n",
      "11 236\n",
      "12 649\n",
      "13 451\n",
      "14 1317\n"
     ]
    }
   ],
   "source": [
    "counts_e = y_test_sub_enough_data.sum(axis=0).values\n",
    "for i,count in enumerate(counts_e):\n",
    "    print(i,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.31\n",
      "1 23.57\n",
      "2 8.42\n",
      "3 18.01\n",
      "4 16.93\n",
      "5 12.99\n",
      "6 28.96\n",
      "7 9.83\n",
      "8 31.02\n",
      "9 28.62\n",
      "10 40.4\n",
      "11 20.37\n",
      "12 7.41\n",
      "13 10.66\n",
      "14 3.65\n"
     ]
    }
   ],
   "source": [
    "counts_e = y_test_sub_enough_data.sum(axis=0).values\n",
    "class_weights = []\n",
    "for i,count in enumerate(counts_e):\n",
    "    print(i,np.round(len(y_test_sub_enough_data)/count,2))\n",
    "    class_weights.append(round(len(y_test_sub_enough_data)/count,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.31,\n",
       " 23.57,\n",
       " 8.42,\n",
       " 18.01,\n",
       " 16.93,\n",
       " 12.99,\n",
       " 28.96,\n",
       " 9.83,\n",
       " 31.02,\n",
       " 28.62,\n",
       " 40.4,\n",
       " 20.37,\n",
       " 7.41,\n",
       " 10.66,\n",
       " 3.65]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598585690515807"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2078+1317+649+571)/len(y_test_sub_enough_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.empty(shape=(len(y_test),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_test[:,:,:,:] = np.array([X[i] for i in test_indexes[1]])\n",
    "\n",
    "\n",
    "X_train_sub = np.empty(shape=(len(y_train_sub),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_train_sub = np.array([X[i] for i in sub_train_indexes[1]])\n",
    "\n",
    "X_test_sub = np.empty(shape=(len(y_test_sub),cnn_pixels,cnn_pixels,colors), dtype=np.uint8)\n",
    "X_test_sub = np.array([X[i] for i in sub_test_indexes[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "##################################################################################################\n",
    "h5file = tables.open_file('Generated_Files/4d_train_data.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_train\", np.array(X_train_sub))\n",
    "h5file.create_array(root, \"y_train\", np.array(y_train_sub))\n",
    "h5file.create_array(root, \"X_test\", np.array(X_test_sub))\n",
    "h5file.create_array(root, \"y_test\", np.array(y_test_sub))\n",
    "h5file.close()\n",
    "\n",
    "h5file = tables.open_file('Generated_Files/4d_test_data.h5', mode='w', title=\"Dataset\")\n",
    "root = h5file.root\n",
    "h5file.create_array(root, \"X_test\", np.array(X_test))\n",
    "h5file.create_array(root, \"y_test\", np.array(y_test))\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Multi Label')\n",
    "print('------------')\n",
    "print('test: ',len(test_indexes[1]),\" \",X_test.shape)\n",
    "print('train: ',len(train_indexes[1]),\" \",X_train.shape)\n",
    "print('   train_test: ',len(sub_test_indexes[1]),\" \",X_test_sub.shape)\n",
    "print('   train_train: ',len(sub_train_indexes[1]),\" \",X_train_sub.shape)\n",
    "\n",
    "print('==============================')\n",
    "\n",
    "print('Single Label')\n",
    "print('------------')\n",
    "print('test: ',len(test_sl_indexes),\" \",X_s_test.shape)\n",
    "print('train: ',len(train_sl_indexes),\" \",X_s_train.shape) # sub components don't exactly add\n",
    "print('   train_test: ',len(test_sl_indexes_sub),\" \",X_s_test_sub.shape)\n",
    "print('   train_train: ',len(train_sl_indexes_sub),\" \",X_s_train_sub.shape)\n",
    "\n",
    "print('==============================')\n",
    "\n",
    "print('Single Label, 2 Categories')\n",
    "print('------------')\n",
    "print('test: ',len(test_s_indexes_2cat),\" \",X_s_test_2cat.shape)\n",
    "print('train: ',len(train_s_indexes_2cat),\" \",X_s_train_2cat.shape) # sub components don't exactly add\n",
    "print('   train_test: ',len(test_s_indexes_sub_2cat),\" \",X_s_test_sub_2cat.shape)\n",
    "print('   train_train: ',len(train_s_indexes_sub_2cat),\" \",X_s_train_sub_2cat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graph_tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-575dc4b51557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphtool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphToolLabelGraphClusterer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStochasticBlockModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticBlockModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_degree_correlation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'real-normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclusterer_graphtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphToolLabelGraphClusterer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_builder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_builder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclusterer_graphtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skmultilearn/cluster/graphtool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graph_tool'"
     ]
    }
   ],
   "source": [
    "from skmultilearn.cluster.graphtool import GraphToolLabelGraphClusterer, StochasticBlockModel\n",
    "model = StochasticBlockModel(nested=False, use_degree_correlation=True, allow_overlap=False, weight_model='real-normal')\n",
    "clusterer_graphtool = GraphToolLabelGraphClusterer(graph_builder=graph_builder, model=model)\n",
    "clusterer_graphtool.fit_predict(None, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_label = clusterer_graphtool.graph_.new_vertex_property(\"string\")\n",
    "\n",
    "for i, v in enumerate(clusterer_graphtool.graph_.vertices()):\n",
    "    node_label[v] = label_names[i][0]\n",
    "\n",
    "clusterer_graphtool.model.model_.draw(vertex_text=node_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
