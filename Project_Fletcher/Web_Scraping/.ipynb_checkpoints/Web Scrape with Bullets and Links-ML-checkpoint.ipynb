{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_30_listings(driver):\n",
    "    # Loop through all 30 entries per page\n",
    "    for post in range(29):\n",
    "        \n",
    "        # Pull job details from the list of jobs on left side of browser window\n",
    "        listing_str = driver.find_element_by_xpath(\"(//li[@class='jl selected'])\").text\n",
    "        listing_int = listing_str.split(\"\\n\")\n",
    "        \n",
    "        # Clean up the data so order of elements is always ['Rating','Job_title','Company','Location', 'Salary_range', 'Status', 'Job_description', 'Company_info'] \n",
    "        if not bool(re.search(r'\\d+.*', listing_int[0])): \n",
    "            listing_int.insert(0, \"\") # If no star rating available, insert a blank\n",
    "        listing_lst = listing_int[0:2] + listing_int[2].split(\" â€“ \") + listing_int[3:] # Split company and location into 2 fields\n",
    "        if 'EASY APPLY' in listing_lst: listing_lst.remove('EASY APPLY') # Remove \"Easy Apply\"\n",
    "        if len(listing_lst) >= 5:\n",
    "                if not bool(re.search(r'\\D\\d+[\\w]\\s*[-]\\D\\s*\\d+\\w+.*', listing_lst[4])): \n",
    "                    listing_lst.insert(4, \"\") # If no estimated salary available, insert a blank\n",
    "        \n",
    "        # Pull full text for job description from right side of browser window\n",
    "        try:\n",
    "            job_description = driver.find_element_by_xpath(\"(//div[@class='jobDescriptionContent desc'])\").text\n",
    "        except:\n",
    "            job_description = '-'\n",
    "        listing_lst.append(job_description)\n",
    "        \n",
    "        # Pull bulleted lists from job description from right side of browser window\n",
    "        try:\n",
    "            job_description_bullets = driver.find_element_by_xpath(\"(//div[@class='jobDescriptionContent desc']//ul[1])\").text\n",
    "        except:\n",
    "            job_description_bullets = '-' \n",
    "        try:\n",
    "            job_description_bullets = job_description_bullets + \" \" + driver.find_element_by_xpath(\"(//div[@class='jobDescriptionContent desc']//ul[2])\").text\n",
    "        except:\n",
    "            pass  \n",
    "        try:\n",
    "            job_description_bullets = job_description_bullets + \" \" + driver.find_element_by_xpath(\"(//div[@class='jobDescriptionContent desc']//ul[3])\").text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            job_description_bullets = job_description_bullets + \" \" + driver.find_element_by_xpath(\"(//div[@class='jobDescriptionContent desc']//ul[3])\").text\n",
    "        except:\n",
    "            pass\n",
    "        listing_lst.append(job_description_bullets)\n",
    "        \n",
    "        # If the company tab exists for this listing, click on it and scrape company info\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"(//li[@data-tab-type='overview'])\").click()\n",
    "            sleep(randint(1000,3000)/1000)\n",
    "            company_str = driver.find_element_by_xpath(\"(//div[@id='EmpBasicInfo'])\").text\n",
    "        except:\n",
    "            company_str = '-'\n",
    "        listing_lst.append(company_str)\n",
    "        \n",
    "        # Get the link to the listing\n",
    "        element = masked_driver.find_element_by_xpath(\"(//li[@class='jl selected']/div/a)\")\n",
    "        link = element.get_attribute('href')\n",
    "        listing_lst.append(link)\n",
    "        \n",
    "        # Turn the data into a pandas Dataframe and add that df to the list, 'frames'\n",
    "        listing_df = pd.DataFrame([listing_lst])\n",
    "        frames.append(listing_df)\n",
    "        \n",
    "        # Click on next job posting from the list on left side of browser window\n",
    "        driver.find_element_by_xpath(\"(//li[@class='jl'])[position()=\" + str(post+1) + \"]\").click()\n",
    "        sleep(randint(1000,3000)/1000)\n",
    "        \n",
    "    # Stack each entry into one large dataframe    \n",
    "    features_df = pd.concat(frames)\n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_next_page(driver):\n",
    "    driver.find_element_by_xpath(\"(//li[@class='next'])\").click()\n",
    "    sleep(randint(3000,5000)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_mult_pages(masked_driver):\n",
    "    \n",
    "    scrape_30_listings(masked_driver)\n",
    "    \n",
    "    for i in range(29):\n",
    "        go_to_next_page(masked_driver)\n",
    "        sleep(randint(500,1000)/1000)\n",
    "        x = scrape_30_listings(masked_driver)\n",
    "        sleep(randint(500,1000)/1000)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Used to test proxy id's\n",
    "\n",
    "# proxy = '79.134.214.186:32424'\n",
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('--proxy-server=%s' % proxy)\n",
    "# masked_driver = webdriver.Chrome(executable_path=\"/Users/user/Documents/chromedriver2\", options=chrome_options)\n",
    "# masked_driver.get(\"https://whatismyipaddress.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_1 = '125.26.7.183:39018'\n",
    "proxy_2 = '200.122.209.78:47220'\n",
    "proxy_3 = '217.21.125.179:56774'\n",
    "proxy_4 = '79.134.214.186:32424'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('--proxy-server=%s' % proxy_1)\n",
    "# masked_driver = webdriver.Chrome(executable_path=\"/Users/user/Documents/chromedriver2\", options=chrome_options)\n",
    "# search_phrase='data+scientist'\n",
    "# masked_driver.get(\"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\" + search_phrase + \"&sc.keyword=\" + search_phrase + \"&locT=N&locId=1&fromAge=1&jobType=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames=[]\n",
    "# data_scientist = collect_mult_pages(masked_driver)\n",
    "# pickle.dump(data_scientist, open( \"data_scientist_posts.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('--proxy-server=%s' % proxy_2)\n",
    "# masked_driver = webdriver.Chrome(executable_path=\"/Users/user/Documents/chromedriver2\", options=chrome_options)\n",
    "# search_phrase='machine+learning'\n",
    "# masked_driver.get(\"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\" + search_phrase + \"&sc.keyword=\" + search_phrase + \"&locT=N&locId=1&fromAge=1&jobType=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames=[]\n",
    "# machine_learning = collect_mult_pages(masked_driver)\n",
    "# pickle.dump(machine_learning, open( \"machine_learning_posts.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--proxy-server=%s' % proxy_3)\n",
    "masked_driver = webdriver.Chrome(executable_path=\"/Users/user/Documents/chromedriver2\", options=chrome_options)\n",
    "search_phrase='artificial+intelligence'\n",
    "masked_driver.get(\"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\" + search_phrase + \"&sc.keyword=\" + search_phrase + \"&locT=N&locId=1&fromAge=1&jobType=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]\n",
    "artificial_intelligence = collect_mult_pages(masked_driver)\n",
    "pickle.dump(artificial_intelligence, open( \"artificial_intelligence_posts.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('--proxy-server=%s' % proxy_4)\n",
    "# masked_driver = webdriver.Chrome(executable_path=\"/Users/user/Documents/chromedriver2\", options=chrome_options)\n",
    "# search_phrase='data+analyst'\n",
    "# masked_driver.get(\"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\" + search_phrase + \"&sc.keyword=\" + search_phrase + \"&locT=N&locId=1&fromAge=1&jobType=\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames=[]\n",
    "# data_analyst = collect_mult_pages(masked_driver)\n",
    "# pickle.dump(data_analyst, open( \"data_analyst_posts.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-606cf0512737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_df' is not defined"
     ]
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.8',\n",
       " 'Data Scientist',\n",
       " 'Amazon',\n",
       " 'Seattle, WA',\n",
       " '$129k-$182k(Glassdoor Est.)',\n",
       " '1 day ago',\n",
       " '-',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull job description from right side of browser window\n",
    "try:\n",
    "    job_description = driver.find_element_by_xpath(\"(//div[@class='jobDescriptionContent desc'])\").text\n",
    "except:\n",
    "    job_description = '-'\n",
    "listing_lst.append(job_description)\n",
    "listing_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the company tab exists for this listing, click on it and scrape company info\n",
    "try:\n",
    "    masked_driver.find_element_by_xpath(\"(//li[@data-tab-type='overview'])\").click()\n",
    "    sleep(randint(1000,3000)/1000)\n",
    "    company_str = masked_driver.find_element_by_xpath(\"(//div[@id='EmpBasicInfo'])\").text\n",
    "except:\n",
    "    company_str = '-'\n",
    "listing_lst.append(company_str)\n",
    "\n",
    "# Turn the data into a pandas Dataframe and add that df to the list, 'frames'\n",
    "listing_df = pd.DataFrame([listing_lst])\n",
    "frames.append(listing_df)\n",
    "\n",
    "# Click on next job posting from the list on left side of browser window\n",
    "masked_driver.find_element_by_xpath(\"(//li[@class='jl'])[position()=\" + str(post+1) + \"]\").click()\n",
    "sleep(randint(1000,3000)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = '125.26.7.183:39018'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--proxy-server=%s' % proxy)\n",
    "masked_driver = webdriver.Chrome(executable_path=\"/Users/user/Documents/chromedriver2\", options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_driver.get(\"https://www.whatismyip.com/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
