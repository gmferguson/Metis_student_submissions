{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: Project McNulty\n",
    "Gretta Ferguosn\n",
    "11/1/18\n",
    "\n",
    "### Motivation\n",
    "Many of us carry our phones with us wherever we go. How much information are we really giving away without realizing it? One particularly valuable type of information comes from the motion sensors on our phones. My project shows that this data tells a clear story about what you are doing. Individuals who are concerned about privacy might find this alarming. On the other hand, companies who want to learn more about you might find this appealing.\n",
    "\n",
    "The obvious example of a company that might use motion data is a fitness company that wants to track your steps or exercise. But many other companies could leverage this data in marketing schemes. For example, if the motion data implies that you are sitting down, then standing up, walking in a circle and then repeating this pattern multiple times, one could reasonably conclude you are trying on shoes. A shoe company could harness these insights and send you just-in-time coupons or marketing material. \n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "The [data](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones#) was gathered by UC Irvine's Center for Machine Learning and Intelligent Systems. To collet the data, each of 30 participants wore a phone attached to a belt as they repeated 6 tasks:\n",
    "1. Walking\n",
    "2. Standing\n",
    "3. Sitting\n",
    "4. Laying\n",
    "5. Walking Up Stairs\n",
    "6. Walking Down Stairs\n",
    "\n",
    "The data was very well balanced across the 6 activity classes. An example of this data collection can be viewed [here](https://www.youtube.com/watch?v=XOEN9W05_4A)\n",
    "\n",
    "A phone is constantly tracking its own motion. The sensors can detect gravity and therefore know which way is \"up\". They can also detect 3 dimensional linear acceleration as well as 3 dimensional angular acceleration (i.e. movements such as pitch, yaw, and roll). To store this information, the researchers used a schema of fixed-width sliding windows of 2.56 sec with 50% overlap. In each such time frame, statistical information was captured about the motion such as acceleration mean, median, max and min, distribution skew, etc. In total I had **561 features across 10,299 data points**.\n",
    "\n",
    "\n",
    "### Model Fitting\n",
    "\n",
    "I fit 8 different models across numerous parameters using GridSearchCV, resulting in a total of 896 unique models fit. A summary of my inputs and best fit parameters is in the table below:\n",
    "\n",
    "| Model  | Parameters tested  | Best fit parameters  | Cross-validated Accuracy Ratio  |\n",
    "|-------|-------------------|---------------------|--------------------------|\n",
    "| Logistic Regression  | 'C': np.logspace(-3,6, 12), 'penalty': ['l1', 'l2'] | 'C': 1.873817422860385, 'penalty': 'l2' | 0.926550598477 |\n",
    "| Support Vector Machines | 'gamma': [.0001,.001,.01,.1, 'scale','auto_deprecated'], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'] | 'gamma': 0.01, 'kernel': 'rbf' | 0.924102285092 |\n",
    "| Extremely Random Forest | 'max_features': [1, 10, 'auto'], 'criterion': ['gini', 'entropy'], 'n_estimators': [100, 200], 'min_samples_split': [2,5,20], 'min_impurity_decrease': [0, 1e-3, 1e-2], 'bootstrap': [True,False], 'max_depth': [3, 10, None]  | 'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'min_impurity_decrease': 0, 'min_samples_split': 5, 'n_estimators': 200 | 0.907644178455 |\n",
    "| Random Forest | 'n_estimators': [50, 200], 'criterion': ['gini', 'entropy'], 'max_depth': [15, 20, None],  'max_features': [10, 15, 50, 'auto'], 'min_samples_split': [2, 5, 25] | 'criterion': 'entropy', 'max_depth': 15, 'max_features': 15, 'min_samples_split': 2, 'n_estimators': 200 | 0.906011969532 |\n",
    "| K nearest Neighbors   | 'n_neighbors': range(1, 100, 2)  | 'n_neighbors':15   | 0.883161044614     |\n",
    "| Decision Tree | 'max_depth': [1,2,3,4,5], 'min_samples_leaf': [3,6,10] | 'max_depth': 5, 'min_samples_leaf': 6 | 0.821953210011 |\n",
    "| Bernoulli Naive Bayes | 'alpha': [.5, 1.0, 5], 'binarize': [0.0, 6.0] | 'alpha': 1.0, 'binarize': 0.0 | 0.82140914037 |\n",
    "| Gaussian Naive Bayes |  'var_smoothing' : [1e-10, 1e-9, 1e-8] | 'var_smoothing': 1e-09 | 0.706882480958 |\n",
    "\n",
    "\n",
    "\n",
    "### Results & Interpretation\n",
    "\n",
    "The best performer was the Logistic regression model with C of 1.87 and L2 (ridge) penalty, which scored 93% accuracy upon training cross-validation. When this model was then fit on the full training data and then applied to the test data, it achieved a 96% accuracy. The high accuracy on both training and test datasets suggests we have a well fit model, without over or underfitting. \n",
    "\n",
    "### Appendix\n",
    "\n",
    "3D PCA data visualization.\n",
    "repeated analysis with 12 category dataset\n",
    "\n",
    "\n",
    "### Tools Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
